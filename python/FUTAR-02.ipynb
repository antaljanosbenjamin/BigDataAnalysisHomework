{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "",
  "signature": "sha256:19f4b4e4e37ce91c977f8aa91f570618c08db98db0862c758abc85cbdabe3a59"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyspark.sql.types\n",
      "from pyspark.sql.types import *\n",
      "from pyspark.sql.functions import *\n",
      "\n",
      "routesSchema = StructType([\n",
      "\tStructField('agency_id',StringType(),True),\n",
      "\tStructField('route_id',StringType(),False),\n",
      "\tStructField('route_short_name',StringType(),False),\n",
      "\tStructField('route_long_name',StringType(),False),\n",
      "\tStructField('route_type',IntegerType(),False),\n",
      "\tStructField('route_desc',StringType(),True),\n",
      "\tStructField('route_color',StringType(),True),\n",
      "\tStructField('route_text_color',StringType(),True)])\n",
      "\n",
      "routes = spark.read.csv('routes.txt', header = True, mode = 'DROPMALFORMED', schema = routesSchema)\n",
      "routes = routes.select(routes.route_id, routes.route_short_name)\n",
      "routes = routes.filter('route_short_name = 7')\n",
      "\n",
      "tripsSchema = StructType([\n",
      "\tStructField('route_id',StringType(),False),\n",
      "\tStructField('trip_id',StringType(),False),\n",
      "\tStructField('service_id',StringType(),False),\n",
      "\tStructField('trip_headsign',StringType(),True),\n",
      "\tStructField('direction_id',IntegerType(),True),\n",
      "\tStructField('block_id',StringType(),True),\n",
      "\tStructField('shape_id',StringType(),True),\n",
      "\tStructField('wheelchair_accessible',IntegerType(),True),\n",
      "\tStructField('bikes_allowed',IntegerType(),True)])\n",
      "\n",
      "trips = spark.read.csv('trips.txt', header = True, mode = 'DROPMALFORMED', schema = tripsSchema);\n",
      "trips = trips.select(trips.route_id, trips.trip_id, trips.service_id)\n",
      "\n",
      "trips = trips.filter(trips.route_id == routes.first().route_id)\n",
      "\n",
      "stopsSchema = StructType([\n",
      "\tStructField('stop_id',StringType(),False),\n",
      "\tStructField('stop_name',StringType(),False),\n",
      "\tStructField('stop_lat',DoubleType(),False),\n",
      "\tStructField('stop_lon',DoubleType(),False),\n",
      "\tStructField('stop_code',StringType(),True),\n",
      "\tStructField('location_type',StringType(),True),\n",
      "\tStructField('parent_station',StringType(),True),\n",
      "\tStructField('wheelchair_boarding',IntegerType(),True),\n",
      "\tStructField('stop_direction',IntegerType(),True)])\n",
      "\n",
      "stops = spark.read.csv('stops.txt', header = True, mode = 'DROPMALFORMED', schema = stopsSchema)\n",
      "stops = stops.select(stops.stop_id, stops.stop_name, stops.parent_station)\n",
      "\n",
      "blahaStations = stops.filter(stops.stop_name.like('Blaha Lujza t\u00e9r%'))\n",
      "blahaStations = blahaStations.select(blahaStations.stop_id, blahaStations.stop_name)\n",
      "renamedBlahaStations = blahaStations.withColumnRenamed('stop_id','station_id').withColumnRenamed('stop_name','station_name')\n",
      "blahaStops = stops.join(renamedBlahaStations, stops.parent_station == renamedBlahaStations.station_id)\n",
      "\n",
      "blahaStops = blahaStops.select(blahaStops.stop_id, blahaStops.stop_name)\n",
      "blahaStops = blahaStops.union(blahaStations).distinct()\n",
      "\n",
      "stopTimesSchema = StructType([\n",
      "\tStructField('trip_id',StringType(),False),\n",
      "\tStructField('stop_id',StringType(),False),\n",
      "\tStructField('arrival_time',StringType(),False),\n",
      "\tStructField('departure_time',StringType(),False),\n",
      "\tStructField('stop_sequence',StringType(),False),\n",
      "\tStructField('shape_dist_traveled',DoubleType(),True)\n",
      "])\n",
      "\n",
      "stopTimes = spark.read.csv('stop_times.txt', header = True, mode = 'DROPMALFORMED', schema = stopTimesSchema)\n",
      "stopTimes = stopTimes.select(stopTimes.trip_id, stopTimes.stop_id)\n",
      "\n",
      "calendarDatesSchema = StructType([\n",
      "    StructField('service_id', StringType(), False),\n",
      "    StructField('date', DateType(), False),\n",
      "    StructField('exception_type', IntegerType(), False)\n",
      "])\n",
      "\n",
      "calendarDates = spark.read.csv(\n",
      "    'calendar_dates.txt', header = True, mode = 'DROPMALFORMED', schema = calendarDatesSchema, dateFormat='yyyyMMdd')\n",
      "\n",
      "tripsAndStopTimes = trips.join(stopTimes, stopTimes.trip_id == trips.trip_id)\n",
      "tripsAndStopsTimesAndStop = tripsAndStopTimes.join(blahaStops, tripsAndStopTimes.stop_id == blahaStops.stop_id)\n",
      "blahaCountPerService = tripsAndStopsTimesAndStop.groupBy('service_id').count()\n",
      "blahaCountPerServicePerDay = calendarDates.join(\n",
      "    blahaCountPerService, blahaCountPerService.service_id == calendarDates.service_id)\n",
      "countOfStopsAtBlaha = blahaCountPerServicePerDay.groupBy().sum('count').first()['sum(count)']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feedInfoSchema = StructType([\n",
      "    StructField('publisher', StringType(), False),\n",
      "    StructField('publisher_url', StringType(), False),\n",
      "    StructField('feed_lang', StringType(), False),\n",
      "    StructField('start_date', DateType(), False),\n",
      "    StructField('end_date', DateType(), False),\n",
      "    StructField('version', StringType(), False),\n",
      "    StructField('ext_version', StringType(), False)\n",
      "])\n",
      "\n",
      "feedInfo = spark.read.csv(\n",
      "    'feed_info.txt', header = True, mode = 'DROPMALFORMED', schema = feedInfoSchema, dateFormat='yyyyMMdd')\n",
      "days = (feedInfo.first()['end_date'] - feedInfo.first()['start_date']).days"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print countOfStopsAtBlaha\n",
      "print days\n",
      "print '%.2f' % ((countOfStopsAtBlaha * 1.0) / days)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13674\n",
        "55\n",
        "248.62\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}